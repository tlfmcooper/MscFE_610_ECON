{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import talib\n",
    "from pylab import plt, mpl\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Conv1D,Flatten,MaxPooling1D,LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, TimeSeriesSplit\n",
    "from pandas_datareader import DataReader\n",
    "from datetime import datetime\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook display imports\n",
    "from IPython.display import set_matplotlib_formats\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "set_matplotlib_formats('retina')\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "random.seed(50) #for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data and Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=datetime(1999, 1, 1)\n",
    "end_date=datetime(2020,9,30)\n",
    "df = DataReader('AAPL',  'yahoo', start=start_date, end=end_date)\n",
    "df.drop(\"Adj Close\",axis=1,inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the first trading of each month as a feature of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year=start_date.year\n",
    "start_month=start_date.month\n",
    "end_year=end_date.year\n",
    "end_month=end_date.month\n",
    "\n",
    "first_days=[]\n",
    "# First year\n",
    "for month in range(start_month,13):\n",
    "    first_days.append(min(df[str(start_year)+\"-\"+str(month)].index))\n",
    "# Other years\n",
    "for year in range(start_year+1,end_year):\n",
    "    for month in range(1,13):\n",
    "        first_days.append(min(df[str(year)+\"-\"+str(month)].index))\n",
    "# Last year\n",
    "for month in range(1,end_month+1):\n",
    "    first_days.append(min(df[str(end_year)+\"-\"+str(month)].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each month we need the means of the month, the first trading day of the current month (and its open price), and the first trading day of the next month (and its open price): our models will predict based on these data.\n",
    "\n",
    "The feature *quot* is the quotient between the open price of the first trading day of the next month and the open price of the first trading day of the current month. This will help capture the variability of the stock price from month to month\n",
    "\n",
    "We also add one year and 2 years moving average to capture some momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data(df):\n",
    "\n",
    "    dfm=df.resample(\"M\").mean()\n",
    "    dfm=dfm[:-1] # As we said, we do not consider the month of end_date\n",
    "    \n",
    "    dfm[\"fd_cm\"]=first_days[:-1]\n",
    "    dfm[\"fd_nm\"]=first_days[1:]\n",
    "    dfm[\"fd_cm_open\"]=np.array(df.loc[first_days[:-1],\"Open\"])\n",
    "    dfm[\"fd_nm_open\"]=np.array(df.loc[first_days[1:],\"Open\"])\n",
    "    dfm[\"quot\"]=dfm[\"fd_nm_open\"].divide(dfm[\"fd_cm_open\"])\n",
    "    \n",
    "    dfm[\"mv_avg_12\"]= dfm[\"Open\"].rolling(window=12).mean().shift(1)\n",
    "    dfm[\"mv_avg_24\"]= dfm[\"Open\"].rolling(window=24).mean().shift(1)\n",
    "    \n",
    "    dfm.dropna(inplace=True)\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm=model_data(df)\n",
    "dfm.head()\n",
    "dfm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions to calculate the Strategy returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_gross(df:pd.DataFrame,v: np.array)-> tuple:\n",
    "    \"\"\"\n",
    "    :param df: dataframe used to model the strategy\n",
    "    :param v: array representiong days in or out of the market 1 for day in and o for day out. The length of the array is the duration of the strategy\n",
    "    :returns (cum_return, average_annual return) tuple of cumulative return and average annual return over the strategy period\n",
    "    \"\"\"\n",
    "    #cumulative return over the period +1\n",
    "    prod=(v*df[\"quot\"]+1-v).prod()\n",
    "    n_years=len(v)/12\n",
    "    return (prod-1)*100,((prod**(1/n_years))-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to compute the net yield.\n",
    "\n",
    "Given any vector of zeros and ones as input, *separate_ones* will return the sequence of vectors of groups of adjacent ones and a scalar equal to the number of groups of adjacent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_ones(u: np.array)-> tuple:\n",
    "    \"\"\"\n",
    "    :param u: array representiong days in or out of the market 1 for day in and o for day out. The length of the array is the duration of the strategy\n",
    "    :returns (out, n): a tuple of a numpy array where each row represents the number of consecutive days in the market and an integer that represents the \n",
    "    total of in and out out of the market\n",
    "    \"\"\"\n",
    "    \n",
    "    u_ = np.r_[0,u,0]\n",
    "    index = np.flatnonzero(u_[:-1] != u_[1:])\n",
    "    v,w = index[::2],index[1::2]\n",
    "    if len(v)==0:\n",
    "        return np.zeros(len(u)),0\n",
    "    \n",
    "    n,m = len(v),len(u)\n",
    "    o = np.zeros(n*m,dtype=int)\n",
    "\n",
    "    r = np.arange(n)*m\n",
    "    o[v+r] = 1\n",
    "\n",
    "    if w[-1] == m:\n",
    "        o[w[:-1]+r[:-1]] = -1\n",
    "    else:\n",
    "        o[w+r] -= 1\n",
    "\n",
    "    out = o.cumsum().reshape(n,-1)\n",
    "    return out,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.array([0,1,1,0,1,1,1,0,1])\n",
    "separate_ones(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_window(data:pd.DataFrame, window_size:int = 1)-> pd.DataFrame:\n",
    "    '''\n",
    "    :param data: dataframe to be used by the model\n",
    "    :param window: this is the look back period on which the LSTM model will train on\n",
    "    :returns data: transformed dataframe including the chosen rolling windows\n",
    "    \n",
    "    '''\n",
    "    data_s = data.copy()\n",
    "    for i in range(window_size):\n",
    "        data = pd.concat([data, data_s.shift(-(i + 1))], axis = 1)\n",
    "        \n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_model(dfm: pd.DataFrame)-> tuple:\n",
    "    '''\n",
    "    :param data: dataframe to be used by the model\n",
    "    :returns (X: np.array, y:np.array): A tuple for the features and targets used for the model\n",
    "    '''\n",
    "    #Standardize the data\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    dg=pd.DataFrame(scaler.fit_transform(dfm[[\"High\",\"Low\",\"Open\",\"Close\",\"Volume\",\"fd_cm_open\",\\\n",
    "                                          \"mv_avg_12\",\"mv_avg_24\",\"fd_nm_open\"]].values))\n",
    "    X=dg[[0,1,2,3,4,5,6,7]]\n",
    "    X=roll_window(X,window)\n",
    "    X=np.reshape(X.values,(X.shape[0],window+1,8))\n",
    "    \n",
    "    y=np.array(dg[8][window:])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of training and testing samples and model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=2\n",
    "X,y=data_to_model(dfm)\n",
    "print(X.shape,y.shape)\n",
    "mtest=60 # number of samples to test\n",
    "X_train=X[:-mtest-1,:,:]\n",
    "X_test=X[-mtest-1:,:,:]\n",
    "y_train=y[:-mtest-1]\n",
    "y_test=y[-mtest-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(300, input_shape = (window,features), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(200,  return_sequences=False)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100,kernel_initializer='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm=model_lstm(window+1,8)\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a callback that will reduce the training rate if training reaches a plateau and stopped progressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=25, verbose=1,\\\n",
    "                                                 factor=0.25, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm=model_lstm.fit(X_train,y_train,epochs=500, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction, EarlyStopping(monitor='loss', restore_best_weights=True, patience=5)],shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm.history['loss']);\n",
    "plt.plot(history_lstm.history['val_loss']);\n",
    "plt.title('model loss');\n",
    "plt.ylabel('loss');\n",
    "plt.xlabel('epoch');\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save_weights(\"lstm_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_lstm=model_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6));\n",
    "plt.plot(y_train, label=\"actual\");\n",
    "plt.plot(y_pred_train_lstm, label=\"prediction by lstm model\");\n",
    "plt.legend(fontsize=10);\n",
    "plt.grid(axis=\"both\");\n",
    "plt.title(\"Actual open price and pedicted one on train set\",fontsize=15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as the predicted price for the next month is greater than the current price, we stay long, otherwise we'll short.The vectors v represents the \"in months\" (as 1s) and \"out months\" (as 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm=model_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lstm=np.diff(y_pred_lstm.reshape(y_pred_lstm.shape[0]),1)\n",
    "v_lstm=np.maximum(np.sign(w_lstm),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6));\n",
    "plt.plot(y_test, label=\"actual\");\n",
    "plt.plot(y_pred_lstm, label=\"prediction lstm\");\n",
    "plt.plot(v_lstm,label=\"In and out lstm\");\n",
    "plt.legend(fontsize=10);\n",
    "plt.grid(axis=\"both\");\n",
    "plt.title(\"Actual open price, predicted ones and vectors on in and out moments\",fontsize=15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare our deep learning trading strategy with the buy and hold strategy. In order to do so, we compute the corresponding vectors *v_bh*, which selects the months in which we are going to stay in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=dfm.iloc[-mtest:,:] \n",
    "v_bh=np.ones(test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gross_portfolio(df,w):\n",
    "    portfolio=[ (w*df[\"quot\"]+(1-w))[:i].prod() for i in range(len(w))]\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6));\n",
    "plt.plot(gross_portfolio(test,v_bh),label=\"Portfolio Buy and Hold\");\n",
    "plt.plot(gross_portfolio(test,v_lstm),label=\"Portfolio LSTM\");\n",
    "plt.legend(fontsize=10);\n",
    "plt.grid(axis=\"both\");\n",
    "plt.title(\"Gross portfolios of the strategy\", fontsize=15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform our performance analysis with Pyfolio, we need to create a dataframe with the predicted returns by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test period of {:.2f} years, from {} to {} \\n\".format(len(v_bh)/12,str(test.loc[test.index[0],\"fd_cm\"])[:10],\\\n",
    "      str(test.loc[test.index[-1],\"fd_nm\"])[:10]))\n",
    "\n",
    "results=pd.DataFrame({})\n",
    "results[\"Method\"]=[\"Buy and hold\",\"LSTM\"]\n",
    "\n",
    "vs=[v_bh,v_lstm]\n",
    "results[\"Total gross yield\"]=[str(round(yield_gross(test,vi)[0],2))+\" %\" for vi in vs]\n",
    "results[\"Annual gross yield\"]=[str(round(yield_gross(test,vi)[1],2))+\" %\" for vi in vs]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and ways to improve the model\n",
    "\n",
    "Although our strategy did not beat the benchmark, it did a satisfactory job of earning a compound annual growth rate(CAGR) of 24.1% which is a very good performance. There are several ways, this model could be improve to earn an even higher CAGR. \n",
    "The first one could have been to break the sample periods into at least 2 or 3 periods because of the structural breaks that occures in 2008-2009( The financial crisis) and the Covid19 pandemic which started in early 2020. We could have then produced one model for each period and concatenate the 3 models to serve as a combined model for our prediction.\n",
    "The second idea could have been to model a two inputs/two outputs model where one input will serve for sentiment analysis and the second input will serve to determine the price of the stock. Then we will only decide whether we are in and out of the market based only on the price direction but also on the sentiment.\n",
    "Finally for all models, we could have performed hyperparameter tuning by performing RandomizedSearchCV to identify the best parmeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "- Advanced Deep Learning with Keras, Zach Deane Meyer, DataCamp,  2019\n",
    "- Machine Learning in Finance,  Nathan George, DataCamp, 2019\n",
    "- Artificial Intelligence in Finance, Yves Hillpsich, Oreilly Media, October 2020\n",
    "- Algorithmic Trading with Keras, Federicko Woelenski, Oreilly Media, 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

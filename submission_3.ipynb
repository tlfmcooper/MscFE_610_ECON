{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import plt, mpl\n",
    "import datetime as dt\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas_datareader import DataReader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "#To ignore all warnings in model output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(50) #for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baba = DataReader('BABA',  'yahoo', datetime(2014,9,14), datetime(2020,10,16))\n",
    "baba = pd.DataFrame(baba.loc[:,'Adj Close'])\n",
    "baba.columns = ['BABA']\n",
    "data = baba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous section lays out the blueprint for vectorized backtesting on the basis of a simple, easy-to-visualize trading strategy. We are going to apply vectorized backtesting to DNN-based trading strategies.The following trains a Keras DNN model. We are going to use the following technical indicators as features in our model.\n",
    "returns, minimun price over a window, maximum price over a window, the momentum indicator and the voloatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(dataframe, symbol, lags=5, features, window=20):\n",
    "    cols = []\n",
    "    df = dataframe.copy()\n",
    "    df.dropna(inplace=True)\n",
    "    df['r'] = np.log(df / df.shift(1))\n",
    "    df['sma'] = df[symbol].rolling(window).mean()\n",
    "    df['min'] = df[symbol].rolling(window).min()\n",
    "    df['max'] = df[symbol].rolling(window).max()\n",
    "    df['mom'] = df['r'].rolling(window).mean()\n",
    "    df['vol'] = df['r'].rolling(window).std()\n",
    "    df.dropna(inplace=True)\n",
    "    df['d'] = np.where(df['r'] > 0, 1, 0)\n",
    "    for f in features:\n",
    "        for lag in range(1, lags + 1):\n",
    "            col = f'{f}_lag_{lag}'\n",
    "            df[col] = df[f].shift(lag)\n",
    "            cols.append(col)\n",
    "    df.dropna(inplace=True)\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose `lags=5` and `features = [symbol, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']` to generate the data for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lags = 5\n",
    "features = [symbol, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']\n",
    "data, cols = add_lags(data, symbol, lags,features, window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['BABA', 'r', 'sma', 'min', 'max', 'mom', 'vol']\n",
    "data, cols = add_lags(data, 'BABA', lags,features, window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hl=2, hu=128, dropout=False, rate=0.3,\n",
    "                 regularize=False, reg=l1(0.0005),\n",
    "                 optimizer=optimizer, input_dim=len(cols)):\n",
    "    model = Sequential()\n",
    "    if not regularize:\n",
    "        reg = None\n",
    "    model.add(Dense(hu, input_dim=input_dim,\n",
    "                          activity_regularizer=reg,\n",
    "                          activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(Dropout(rate, seed=100))\n",
    "    for _ in range(hl):\n",
    "        model.add(Dense(hu, activation='relu',\n",
    "                        activity_regularizer=reg))\n",
    "        if dropout:\n",
    "            model.add(Dropout(rate, seed=100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                   metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train-test split the historical data on a sequential manner, and train the DNN model based on normalized features data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit #better way of splitting to be used later after successfully running first version of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of training and testing samples and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use 10% of the samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_numbers = data.shape[0]\n",
    "test_sample = int(0.1 * sample_numbers)\n",
    "#delta =dt.timedelta(-test_sample)\n",
    "#split_point = data.index[-1] + delta\n",
    "split_point = list(data.index)[sample_numbers - test_sample]\n",
    "train = data.loc[:split_point].copy()\n",
    "test = data.loc[split_point:]\n",
    "#scaler = StandardScaler()\n",
    "mu, std = train.mean(), train.std()\n",
    "train_ = (train - mu) / std\n",
    "test = data.loc[split_point:].copy()\n",
    "test_ = (test - mu) / std\n",
    "#train_ = scaler.fit_transform(train)\n",
    "model = create_model(hl=2, hu=64, dropout=True, regularize=True)\n",
    "model.fit(train_[cols], train['d'],\n",
    "                 epochs=20, verbose=False,\n",
    "                 validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_[cols], train['d']) \n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized backtesting can now be applied to judge the economic performance of the DNN-based trading strategy in-sample based on the modelâ€™s predictions.\n",
    "In this context, an upward prediction is naturally interpreted as a long position and a downward prediction as a short position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['p'] = np.where(model.predict(train_[cols]) > 0.5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,['p','r']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['s'] = train['p'] * train['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,['p','r','s']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_returns = train[['r', 's']].add(1).cumprod().sub(1)\n",
    "cumulative_returns.plot(figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_[cols], test['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['p'] = np.where(model.predict(test_[cols]) > 0.5, 1, -1)\n",
    "test['p'].value_counts()\n",
    "test['s'] = test['p'] * test['r']\n",
    "cumulative_returns_test = test[['r', 's']].add(1).cumprod().sub(1)\n",
    "cumulative_returns_test.plot(figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['p'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas to improve the model\n",
    "- Add addtitional indicators such bollingers band, etc (checkout the packages for algorithmic trading)\n",
    "- suggest adding sentiment analysis, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "Calculate Sharpe Ratio, Maxdrawdown, ... etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add references\n",
    "- Machine learning for AI, Yves Ipsich\n",
    "- [python for trading](https://www.datacamp.com/community/tutorials/finance-python-trading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
